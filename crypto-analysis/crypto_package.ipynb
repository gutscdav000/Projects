{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, pickle, quandl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "import time\n",
    "import math\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "py.init_notebook_mode(connected = True)\n",
    "\n",
    "\n",
    "########################################################################\n",
    "#                        API Functions\n",
    "########################################################################\n",
    "\n",
    "#purpose: download and cache a Quandl dataseries\n",
    "#signature: get_quandle_data(quandl_id: ) -> df: pandas dataframe\n",
    "## *** quandl API key = WZpC82bNrwpdw59PaRK1\n",
    "def get_quandl_data(quandl_id):\n",
    "    home = os.getcwd()\n",
    "    \n",
    "    # create directory if it doesn't already exist\n",
    "    if 'quandl_cache' not in os.listdir(home):\n",
    "        os.mkdir('quandl_cache')\n",
    "    \n",
    "    #change directory to quandl_cache\n",
    "    path = os.path.join(home, 'quandl_cache/')\n",
    "    os.chdir(path)\n",
    "        \n",
    "    # download & cache\n",
    "    cache_path = 'quandl_cache/{}.pkl'.format(quandl_id).replace('/','-')\n",
    "    try:\n",
    "        #serialize python object structure\n",
    "        file = open(cache_path, 'rb')\n",
    "        df = pickle.load(file)\n",
    "        print('Loaded {} from cache'.format(quandl_id))\n",
    "    except (OSError, IOError) as e:\n",
    "        print('Downloading {} frpm Quandl'.format(quandl_id))\n",
    "        df = quandl.get(quandl_id, returns = \"pandas\")\n",
    "        df.to_pickle(cache_path)\n",
    "        print('Cached {} at {}'.format(quandl_id, cache_path))\n",
    "        \n",
    "    os.chdir('../') \n",
    "    return df\n",
    "\n",
    "\n",
    "# purpose: merge common column of each dataframe into combined dataframe\n",
    "# signature: merge_dfs_on_column(dataframes: list, labels: list, col: String) \n",
    "# -> pd.DataFrame(series_dict): dataframe\n",
    "def merge_dfs_on_column(dataframes, labels, col):\n",
    "    series_dict = {labels[i] : dataframes[i][col] for i in range(len(dataframes))}\n",
    "    return pd.DataFrame(series_dict)\n",
    "\n",
    "# purpose: \n",
    "# signature: df_scatter(df:dataframe, title, seperate_y_axis:Boolean, y_axis_label:String, scale:String, initial_hide:boolean) \n",
    "# -> ploty scatter plot\n",
    "def df_scatter(df, title, seperate_y_axis = False, y_axis_label='', scale='linear', initial_hide=False): \n",
    "    label_arr = list(df)\n",
    "    # lambda to be used for form trace\n",
    "    series_arr = list(map(lambda col: df[col], label_arr))\n",
    "    \n",
    "    # plot layout config\n",
    "    layout = go.Layout(\n",
    "        title=title,\n",
    "        legend=dict(orientation=\"h\"),\n",
    "        xaxis=dict(type='date'),\n",
    "        yaxis=dict(\n",
    "            title=y_axis_label,\n",
    "            showticklabels= not seperate_y_axis,\n",
    "            type=scale\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    y_axis_config = dict(\n",
    "        overlaying='y',\n",
    "        showticklabels=False,\n",
    "        type=scale )\n",
    "    \n",
    "    visibility = 'visible'\n",
    "    if initial_hide:\n",
    "        visibility = 'legendonly'\n",
    "        \n",
    "    # Form Trace for each series\n",
    "    trace_arr = []\n",
    "    for index, series in enumerate(series_arr):\n",
    "        trace = go.Scatter(\n",
    "            x=series.index, \n",
    "            y=series, \n",
    "            name=label_arr[index],\n",
    "            visible=visibility\n",
    "        )\n",
    "        \n",
    "        # add separate axis for series \n",
    "        if seperate_y_axis:\n",
    "            trace['yaxis'] = 'y{}'.format(index + 1)\n",
    "            layout['yaxis{}'.format(index + 1)] = y_axis_config  \n",
    "        \n",
    "        trace_arr.append(trace)\n",
    "    \n",
    "    fig = go.Figure(data = trace_arr, layout = layout)\n",
    "    py.iplot(fig)\n",
    "    \n",
    "# purpose: Download and cache JSON data, return as a dataframe.\n",
    "# signature: get_json_data(json_url:String, cache_path:String)\n",
    "# -> df: dataframe\n",
    "def get_json_data(json_url, cache_path): \n",
    "    try:        \n",
    "        f = open(cache_path, 'rb')\n",
    "        df = pickle.load(f)   \n",
    "        print('Loaded {} from cache'.format(cache_path)) #was json object\n",
    "    except (OSError, IOError) as e:\n",
    "        print('Downloading {}'.format(json_url))\n",
    "        df = pd.read_json(json_url)\n",
    "        df.to_pickle(cache_path)\n",
    "        print('Cached {} at {}'.format(json_url, cache_path))\n",
    "    return df\n",
    "    \n",
    "    \n",
    "#purpose: retrieve crypto data from poloniex \n",
    "#signiture: get_crypto_data(poloniex_pair:String) -> data_df: dataframe\n",
    "def get_crypto_data(poloniex_pair):\n",
    "    BASE_POLO_URL = 'https://poloniex.com/public?command=returnChartData&currencyPair={}&start={}&end={}&period={}'\n",
    "    start_date = datetime.strptime('2015-01-01', '%Y-%m-%d') # get data from start of 2015\n",
    "    end_date = datetime.now()\n",
    "    period = 86400 # pull daily data (86,400 seconds per day)\n",
    "    \n",
    "    # use time() instead of timestamp() with python 2\n",
    "    #json_url = BASE_POLO_URL.format(poloniex_pair, start_date.time(), end_date.time(), period)\n",
    "    json_url = BASE_POLO_URL.format(poloniex_pair, start_date.timestamp(), end_date.timestamp(), period)\n",
    "    #json_url = BASE_POLO_URL.format(poloniex_pair, start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'), period)\n",
    "    \n",
    "    \n",
    "    data_df = get_json_data(json_url, poloniex_pair)\n",
    "    data_df = data_df.set_index('date')\n",
    "    return data_df\n",
    "\n",
    "def get_serialized_crypto_data(poloniex_pair, serializedCoinPath):\n",
    "    BASE_POLO_URL = 'https://poloniex.com/public?command=returnChartData&currencyPair={}&start={}&end={}&period={}'\n",
    "    start_date = datetime.strptime('2015-01-01', '%Y-%m-%d') # get data from start of 2015\n",
    "    end_date = datetime.now()\n",
    "    period = 86400 # pull daily data (86,400 seconds per day)\n",
    "    \n",
    "    # use time() instead of timestamp() with python 2\n",
    "    #json_url = BASE_POLO_URL.format(poloniex_pair, start_date.time(), end_date.time(), period)\n",
    "    json_url = BASE_POLO_URL.format(poloniex_pair, start_date.timestamp(), end_date.timestamp(), period)\n",
    "    #json_url = BASE_POLO_URL.format(poloniex_pair, start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'), period)\n",
    "    \n",
    "#     try:\n",
    "#         data_df = get_json_data(json_url, serializedCoinPath)\n",
    "#     except FileNotFoundError as e1:\n",
    "        \n",
    "#         except (OSError, IOError) as e2:\n",
    "            \n",
    "        \n",
    "    data_df = get_json_data(json_url, serializedCoinPath)#poloniex_pair\n",
    "    data_df = data_df.set_index('date')\n",
    "    return data_df\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "# a function which takes two numpy arrays of equal size and calculates\n",
    "# the pearson correlation coefficient for the two sets of data\n",
    "# @params 2 numpy arrays\n",
    "# @returns a float corresponding to the pearson r value\n",
    "def pearson_coefficient(npX, npY):\n",
    "    if len(npX) != len(npY):\n",
    "        return -23\n",
    "    \n",
    "    n = len(npX)\n",
    "    x2 = 0\n",
    "    y2 = 0\n",
    "    x = 0\n",
    "    y = 0\n",
    "    xy = 0\n",
    "    \n",
    "    #sum coefficient parameters\n",
    "    for i in range(n):\n",
    "        x2 += npX[i] ** 2\n",
    "        y2 += npY[i] ** 2\n",
    "        x += npX[i]\n",
    "        y += npY[i]\n",
    "        xy += npX[i] * npY[i]\n",
    "\n",
    "    coef = float((xy - ((x * y)/n)) /math.sqrt((x2 - ((x ** 2) / n)) * (y2 - ((y ** 2) / n))))\n",
    "    \n",
    "    return coef\n",
    "\n",
    "\n",
    "#purpose: This is a new function for correlating two crypto coins via a plot\n",
    "# crypto_correlation(pandas.DataFrame, string, pandas.DataFrame, string) \n",
    "# --> *returns: pearson coeff *prints: Plot\n",
    "def crypto_correlation(df_left, name1, df_right, name2, plotBool=False):\n",
    "    #make sure dates match && read df into arrays\n",
    "    left_returns, right_returns = match_dates(df_left, name1, df_right, name2)\n",
    "    print(str(len(left_returns)),str(len(right_returns)))\n",
    "    \n",
    "    # calculate values for linear regression\n",
    "    slope, intercept, r_val, p_val, std_err = stats.linregress(left_returns, right_returns)\n",
    "    \n",
    "    best_fit_x = np.arange(min(left_returns), max(left_returns), (max(left_returns)- min(left_returns)) / 10000.0)#not sure this is right for my model?\n",
    "    print(\"slope:\", slope, \"\\tintercept:\", intercept)\n",
    "    best_fit_y = slope * best_fit_x + intercept\n",
    "    plot = [go.Scatter(\n",
    "        x = left_returns,\n",
    "        y = right_returns,\n",
    "        name = str(name1).title() + \"vs. \" + str(name2).title() + \"Correlation\",\n",
    "        mode = 'markers',\n",
    "        marker = dict(\n",
    "            size = 10,\n",
    "            color = 'rgba(255, 0, 0, .9)',\n",
    "            line = dict(width = 2,)\n",
    "        )\n",
    "    ), go.Scatter(x = best_fit_x,\n",
    "                  y = best_fit_y,\n",
    "                  mode='lines',\n",
    "                  marker=go.Marker(color='rgb(31, 119, 180)'),\n",
    "                  name='Fit'\n",
    "              )]\n",
    "    layout = dict( \n",
    "        title = str(name1)+ ' vs. '+str(name2)+' correlation',\n",
    "        #yaxis = dict(zeroline = False),\n",
    "        #xaxis = dict(zeroline = False)\n",
    "    )\n",
    "          \n",
    "    if plotBool:\n",
    "       fig = dict(data=plot,layout=layout)\n",
    "       py.iplot(fig, filename='plot')\n",
    "    \n",
    "    return pearson_coefficient(left_returns, right_returns)\n",
    "\n",
    "\n",
    "\n",
    "#(HELPER FOR crypto_correlation function)date match function\n",
    "# purpose: returns 2 numpy arrays of daily returns for corresponding days of 2 different currencies\n",
    "# match_dates(left_df: dataframe, right_df: dataframe) -> np.Array, np.Array\n",
    "def match_dates(left_df, symbol1, right_df, symbol2):\n",
    "    \n",
    "    # merge dataframes on the date (e.g. the index of the df)\n",
    "    merged_df = pd.merge(left_df, right_df, how = 'inner', left_index=True, right_index=True)#, validate = \"one_to_one\"\n",
    "    #######################################################################\n",
    "    # so it's merging on date, but I need to differentiate between prices of each currency\n",
    "    #######################################################################\n",
    "    \n",
    "    lst1 = []\n",
    "    lst2 = []\n",
    "    \n",
    "    #actually range of merged \n",
    "    range_df = range(len(merged_df) - 1)\n",
    "\n",
    "    # calculate daily returns\n",
    "    for i in range_df:\n",
    "        lst1.append((merged_df['price_usd_x'][i + 1] - merged_df['price_usd_x'][i]) / merged_df['price_usd_x'][i])\n",
    "        #print(\"i:\", i, \"\\trange\\[-1\\]\",range_df[-1])\n",
    "        #if i < range_df[-1]:\n",
    "        lst2.append((merged_df['price_usd_y'][i + 1] - merged_df['price_usd_y'][i]) / merged_df['price_usd_y'][i])\n",
    "        \n",
    "    # return 2 numpy arrays containing daily returns for matching dates\n",
    "    npA1 = np.array(lst1)\n",
    "    npA2 = np.array(lst2)\n",
    "\n",
    "    return npA1, npA2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below retrieves bitcoin and altcoin data and computes the pearson values for a matrix where the rows and columns are represented by the altcoins list where i,j = 0 -> ETH,ETH and i,j = 7 -> GNT,GNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BTC_ETH from cache\n",
      "Loaded BTC_LTC from cache\n",
      "Loaded BTC_XRP from cache\n",
      "Loaded BTC_ETC from cache\n",
      "Loaded BTC_DASH from cache\n",
      "Loaded BTC_XMR from cache\n",
      "Loaded BTC_XEM from cache\n",
      "Loaded BTC_GNT from cache\n",
      "Loaded BCHARTS/KRAKENUSD from cache\n",
      "Loaded BCHARTS/COINBASEUSD from cache\n",
      "Loaded BCHARTS/BITSTAMPUSD from cache\n",
      "Loaded BCHARTS/ITBITUSD from cache\n",
      "Loaded BCHARTS/OKCOINUSD from cache\n",
      "Loaded BCHARTS/GETBTCUSD from cache\n",
      "878 878\n",
      "slope: 1.0 \tintercept: 0.0\n",
      "878 878\n",
      "slope: 0.203199597598 \tintercept: 0.00408444747289\n",
      "878 878\n",
      "slope: 0.151533292588 \tintercept: 0.00727397609035\n",
      "527 527\n",
      "slope: 0.479316710539 \tintercept: 0.00598545637588\n",
      "878 878\n",
      "slope: 0.236314278873 \tintercept: 0.00571015226461\n",
      "878 878\n",
      "slope: 0.245515930354 \tintercept: 0.00679166007895\n",
      "878 878\n",
      "slope: 0.237442147222 \tintercept: 0.0116290077862\n",
      "318 318\n",
      "slope: 0.809856885822 \tintercept: 0.00227038240919\n",
      "878 878\n",
      "slope: 0.313542606139 \tintercept: 0.00784650498465\n",
      "1096 1096\n",
      "slope: 1.0 \tintercept: 0.0\n",
      "1096 1096\n",
      "slope: 0.340381910931 \tintercept: 0.00433168659736\n",
      "527 527\n",
      "slope: 0.403306873698 \tintercept: 0.00665970619224\n",
      "1096 1096\n",
      "slope: 0.256708366744 \tintercept: 0.00572170472895\n",
      "1096 1096\n",
      "slope: 0.33467834004 \tintercept: 0.00618538422057\n",
      "1008 1008\n",
      "slope: 0.384946460468 \tintercept: 0.0088704908021\n",
      "318 318\n",
      "slope: 0.540363382944 \tintercept: 0.0061285756324\n",
      "878 878\n",
      "slope: 0.120109581461 \tintercept: 0.00869713203438\n",
      "1096 1096\n",
      "slope: 0.211133249114 \tintercept: 0.00429246918431\n",
      "1096 1096\n",
      "slope: 1.0 \tintercept: 0.0\n",
      "527 527\n",
      "slope: 0.0556342749545 \tintercept: 0.00977215477625\n",
      "1096 1096\n",
      "slope: 0.0892724502342 \tintercept: 0.00660471766032\n",
      "1096 1096\n",
      "slope: 0.123669293319 \tintercept: 0.00729114441391\n",
      "1008 1008\n",
      "slope: 0.233668646326 \tintercept: 0.00953539864569\n",
      "318 318\n",
      "slope: 0.201448045517 \tintercept: 0.0100184078743\n",
      "527 527\n",
      "slope: 0.138131946347 \tintercept: 0.0081205703583\n",
      "527 527\n",
      "slope: 0.146411023679 \tintercept: 0.00816702868017\n",
      "527 527\n",
      "slope: 0.0400753369783 \tintercept: 0.0140634565605\n",
      "527 527\n",
      "slope: 1.0 \tintercept: 0.0\n",
      "527 527\n",
      "slope: 0.114205157857 \tintercept: 0.00961162154549\n",
      "527 527\n",
      "slope: 0.0841472638665 \tintercept: 0.0115999316111\n",
      "527 527\n",
      "slope: 0.111703069395 \tintercept: 0.011476760447\n",
      "318 318\n",
      "slope: 0.684246468253 \tintercept: 0.00592816835233\n",
      "878 878\n",
      "slope: 0.396439017085 \tintercept: 0.00657124762002\n",
      "1096 1096\n",
      "slope: 0.285095929496 \tintercept: 0.0035683888301\n",
      "1096 1096\n",
      "slope: 0.159837356751 \tintercept: 0.00509656431527\n",
      "527 527\n",
      "slope: 0.370471882814 \tintercept: 0.00656975470459\n",
      "1096 1096\n",
      "slope: 1.0 \tintercept: 0.0\n",
      "1096 1096\n",
      "slope: 0.36391306208 \tintercept: 0.00545669510016\n",
      "1008 1008\n",
      "slope: 0.355758988969 \tintercept: 0.00892618756601\n",
      "318 318\n",
      "slope: 0.508847022317 \tintercept: 0.00723855255488\n",
      "878 878\n",
      "slope: 0.254729908762 \tintercept: 0.00740853420241\n",
      "1096 1096\n",
      "slope: 0.252225742538 \tintercept: 0.00357651902742\n",
      "1096 1096\n",
      "slope: 0.150256588134 \tintercept: 0.00502978337266\n",
      "527 527\n",
      "slope: 0.178457387378 \tintercept: 0.00834920723136\n",
      "1096 1096\n",
      "slope: 0.246949672251 \tintercept: 0.00517073835621\n",
      "1096 1096\n",
      "slope: 1.0 \tintercept: 0.0\n",
      "1008 1008\n",
      "slope: 0.192064575459 \tintercept: 0.00985764038325\n",
      "318 318\n",
      "slope: 0.670569580709 \tintercept: 0.00640150143599\n",
      "878 878\n",
      "slope: 0.131967375374 \tintercept: 0.00790812320894\n",
      "1008 1008\n",
      "slope: 0.156484449504 \tintercept: 0.00467759446926\n",
      "1008 1008\n",
      "slope: 0.158312407368 \tintercept: 0.00598998225043\n",
      "527 527\n",
      "slope: 0.188266655368 \tintercept: 0.00819500022715\n",
      "1008 1008\n",
      "slope: 0.118971341867 \tintercept: 0.00547654794711\n",
      "1008 1008\n",
      "slope: 0.100793381398 \tintercept: 0.00665225959192\n",
      "1008 1008\n",
      "slope: 1.0 \tintercept: 0.0\n",
      "318 318\n",
      "slope: 0.433992936575 \tintercept: 0.00608216354893\n",
      "318 318\n",
      "slope: 0.348167223332 \tintercept: 0.0103429399519\n",
      "318 318\n",
      "slope: 0.336236445288 \tintercept: 0.0111128010632\n",
      "318 318\n",
      "slope: 0.239901578471 \tintercept: 0.0203156664538\n",
      "318 318\n",
      "slope: 0.381251977336 \tintercept: 0.00735306194527\n",
      "318 318\n",
      "slope: 0.240758368325 \tintercept: 0.0113442303328\n",
      "318 318\n",
      "slope: 0.288873129972 \tintercept: 0.0082822170649\n",
      "318 318\n",
      "slope: 0.39486053592 \tintercept: 0.0142961548355\n",
      "318 318\n",
      "slope: 1.0 \tintercept: 0.0\n",
      "label\t\t pearson value\n",
      "type:\t <class 'float'>\n",
      "sys.float_info(max=1.7976931348623157e+308, max_exp=1024, max_10_exp=308, min=2.2250738585072014e-308, min_exp=-1021, min_10_exp=-307, dig=15, mant_dig=53, epsilon=2.220446049250313e-16, radix=2, rounds=1)\n",
      "[1.0, 0.2524118289565168, 0.13490960065966898, 0.25731099887733594, 0.30607874875530394, 0.2500804881208606, 0.1770158664413733, 0.5310043533088485]\n",
      "[0.2524118289565168, 1.0, 0.26807823260114105, 0.2429991198235532, 0.27053005457118656, 0.290541723041482, 0.24543458386045724, 0.426250939054212]\n",
      "[0.13490960065966898, 0.26807823260114105, 1.0, 0.04721824135163039, 0.11945322296250607, 0.13631627221669051, 0.1923347236625999, 0.219835629731469]\n",
      "[0.25731099887733594, 0.2429991198235532, 0.04721824135163039, 1.0, 0.2056934609035937, 0.12254264916591456, 0.14501711371175988, 0.5107546563726081]\n",
      "[0.30607874875530394, 0.27053005457118656, 0.11945322296250607, 0.2056934609035937, 1.0, 0.2997802718800544, 0.20573070820576067, 0.35001311235420585]\n",
      "[0.2500804881208606, 0.290541723041482, 0.13631627221669051, 0.12254264916591456, 0.2997802718800544, 1.0, 0.1391360413665691, 0.44012445244876547]\n",
      "[0.1770158664413733, 0.24543458386045724, 0.1923347236625999, 0.14501711371175988, 0.20573070820576067, 0.1391360413665691, 1.0, 0.41396459211094533]\n",
      "[0.5310043533088485, 0.426250939054212, 0.219835629731469, 0.5107546563726081, 0.35001311235420585, 0.44012445244876547, 0.41396459211094533, 1.0]\n"
     ]
    }
   ],
   "source": [
    "import os, pickle, quandl, time, math, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "\n",
    "########################################################\n",
    "# compile data\n",
    "########################################################\n",
    "\n",
    "# exchange info\n",
    "altcoins = ['ETH','LTC','XRP','ETC','DASH','XMR','XEM', 'GNT']\n",
    "alt_data = {}\n",
    "\n",
    "#change dir to poloniex_cache & create dir if it doesn't exist \n",
    "if not 'poloniex_cache' in os.listdir(os.getcwd()):\n",
    "    os.mkdir('poloniex_cache')\n",
    "    \n",
    "path = os.path.join(os.getcwd(), 'poloniex_cache')\n",
    "os.chdir(path)\n",
    "\n",
    "for alt in altcoins:\n",
    "    coinpair = 'BTC_{}'.format(alt)\n",
    "    crypto_price_df = get_serialized_crypto_data(coinpair, coinpair)\n",
    "    #crypto_price_df = get_serialized_crypto_data(coinpair, os.path.join('poloniex_cache',coinpair))\n",
    "    alt_data[alt] = crypto_price_df\n",
    "\n",
    "#leave the directory\n",
    "os.chdir('../')\n",
    "\n",
    "exchanges = ['KRAKEN','COINBASE', 'BITSTAMP','ITBIT','OKCOIN', 'GETBTC']#,'COINSBANK','HITBTC','LYBIT','ANXHK','BITME','BITBOX','INTRSNG','BTCE','WEEX','JUST','CBX']\n",
    "exch_data = {}\n",
    "# retrieve exchange data and read into dictionary\n",
    "for exchange in exchanges:\n",
    "    exchange_df = get_quandl_data('BCHARTS/{}USD'.format(exchange))\n",
    "    #time.sleep(1000)\n",
    "    exch_data[exchange] = exchange_df\n",
    "    \n",
    "# Merge BTC price data series' into single dataframe\n",
    "btc_usd_datasets = merge_dfs_on_column(list(exch_data.values()), list(exch_data.keys()), 'Weighted Price')\n",
    "btc_usd_datasets.replace(0, np.nan, inplace = True) # remove 0 values\n",
    "# Calc avg in new column\n",
    "btc_usd_datasets['avg_btc_price_usd'] = btc_usd_datasets.mean(axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "# calculate USD Price as new col in each dataframe\n",
    "for alt in alt_data.keys():\n",
    "    alt_data[alt]['price_usd'] = alt_data[alt]['weightedAverage'] * btc_usd_datasets['avg_btc_price_usd']\n",
    "    \n",
    "\n",
    "########################################################\n",
    "# organize into daily returns\n",
    "########################################################\n",
    "dailyReturns = {}\n",
    "\n",
    "for alt in alt_data.keys():\n",
    "    dailyReturns[alt] = np.empty(len(alt_data[alt]['price_usd']) - 1)\n",
    "    for i in range(len(alt_data[alt]['price_usd']) - 1):\n",
    "        # calculate returns for day\n",
    "        dayRet = (alt_data[alt]['price_usd'][i + 1] - alt_data[alt]['price_usd'][i]) / alt_data[alt]['price_usd'][i]\n",
    "        #insert them into numpy array\n",
    "        np.insert(dailyReturns[alt], i, dayRet)\n",
    "\n",
    "        \n",
    "#matrix to contain preprocessed pearson correlation values between currencies\n",
    "pearsonValueMatrix = np.empty([len(alt_data.keys()), len(alt_data.keys())])\n",
    "completed = {}\n",
    "indexVector = []\n",
    "i = 0\n",
    "j = 0\n",
    "pVal = []\n",
    "\n",
    "# create the file\n",
    "file = open('crypto_pearson.txt', 'w')\n",
    "for a1 in alt_data.keys():\n",
    "    indexVector.append(i)\n",
    "    tmp = []\n",
    "    for a2 in alt_data.keys():\n",
    "        #calculate pearson value and print plot\n",
    "        str1 = a1 + \",\" + a2\n",
    "        completed[str1] = crypto_correlation(alt_data[a1], a1, alt_data[a2], a2, False)\n",
    "        tmp.append(completed[str1])\n",
    "        np.insert(pearsonValueMatrix, [i,j], completed[str1])\n",
    "        j += 1\n",
    "        #append value to file\n",
    "        file.write(str(completed[str1]) + ',')\n",
    "    file.write('\\n')\n",
    "\n",
    "    pVal.append(tmp)\n",
    "    i += 1\n",
    "file.write(\"\\n\")\n",
    "file.write(str(altcoins))\n",
    "#close the file\n",
    "file.close()\n",
    "\n",
    "\n",
    "#print(pearsonValueMatrix)\n",
    "print(\"label\\t\\t\", \"pearson value\")\n",
    "print(\"type:\\t\", type(pVal[0][0]))\n",
    "print(sys.float_info)\n",
    "for it in pVal:    \n",
    "    print(it)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
