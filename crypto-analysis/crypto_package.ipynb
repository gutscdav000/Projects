{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, pickle, quandl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "import time\n",
    "\n",
    "py.init_notebook_mode(connected = True)\n",
    "\n",
    "\n",
    "########################################################################\n",
    "#                        API Functions\n",
    "########################################################################\n",
    "\n",
    "#purpose: download and cache a Quandl dataseries\n",
    "#signature: get_quandle_data(quandl_id: ) -> df: pandas dataframe\n",
    "## *** quandl API key = WZpC82bNrwpdw59PaRK1\n",
    "def get_quandl_data(quandl_id):\n",
    "    home = os.getcwd()\n",
    "    \n",
    "    # create directory if it doesn't already exist\n",
    "    if 'quandl_cache' not in os.listdir(home):\n",
    "        os.mkdir('quandl_cache')\n",
    "    \n",
    "    #change directory to quandl_cache\n",
    "    path = os.path.join(home, 'quandl_cache/')\n",
    "    os.chdir(path)\n",
    "        \n",
    "    # download & cache\n",
    "    cache_path = 'quandl_cache/{}.pkl'.format(quandl_id).replace('/','-')\n",
    "    try:\n",
    "        #serialize python object structure\n",
    "        file = open(cache_path, 'rb')\n",
    "        df = pickle.load(file)\n",
    "        print('Loaded {} from cache'.format(quandl_id))\n",
    "    except (OSError, IOError) as e:\n",
    "        print('Downloading {} frpm Quandl'.format(quandl_id))\n",
    "        df = quandl.get(quandl_id, returns = \"pandas\")\n",
    "        df.to_pickle(cache_path)\n",
    "        print('Cached {} at {}'.format(quandl_id, cache_path))\n",
    "        \n",
    "    os.chdir('../') \n",
    "    return df\n",
    "\n",
    "\n",
    "# purpose: merge common column of each dataframe into combined dataframe\n",
    "# signature: merge_dfs_on_column(dataframes: list, labels: list, col: String) \n",
    "# -> pd.DataFrame(series_dict): dataframe\n",
    "def merge_dfs_on_column(dataframes, labels, col):\n",
    "    series_dict = {labels[i] : dataframes[i][col] for i in range(len(dataframes))}\n",
    "    return pd.DataFrame(series_dict)\n",
    "\n",
    "# purpose: \n",
    "# signature: df_scatter(df:dataframe, title, seperate_y_axis:Boolean, y_axis_label:String, scale:String, initial_hide:boolean) \n",
    "# -> ploty scatter plot\n",
    "def df_scatter(df, title, seperate_y_axis = False, y_axis_label='', scale='linear', initial_hide=False): \n",
    "    label_arr = list(df)\n",
    "    # lambda to be used for form trace\n",
    "    series_arr = list(map(lambda col: df[col], label_arr))\n",
    "    \n",
    "    # plot layout config\n",
    "    layout = go.Layout(\n",
    "        title=title,\n",
    "        legend=dict(orientation=\"h\"),\n",
    "        xaxis=dict(type='date'),\n",
    "        yaxis=dict(\n",
    "            title=y_axis_label,\n",
    "            showticklabels= not seperate_y_axis,\n",
    "            type=scale\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    y_axis_config = dict(\n",
    "        overlaying='y',\n",
    "        showticklabels=False,\n",
    "        type=scale )\n",
    "    \n",
    "    visibility = 'visible'\n",
    "    if initial_hide:\n",
    "        visibility = 'legendonly'\n",
    "        \n",
    "    # Form Trace for each series\n",
    "    trace_arr = []\n",
    "    for index, series in enumerate(series_arr):\n",
    "        trace = go.Scatter(\n",
    "            x=series.index, \n",
    "            y=series, \n",
    "            name=label_arr[index],\n",
    "            visible=visibility\n",
    "        )\n",
    "        \n",
    "        # add separate axis for series \n",
    "        if seperate_y_axis:\n",
    "            trace['yaxis'] = 'y{}'.format(index + 1)\n",
    "            layout['yaxis{}'.format(index + 1)] = y_axis_config  \n",
    "        \n",
    "        trace_arr.append(trace)\n",
    "    \n",
    "    fig = go.Figure(data = trace_arr, layout = layout)\n",
    "    py.iplot(fig)\n",
    "    \n",
    "# purpose: Download and cache JSON data, return as a dataframe.\n",
    "# signature: get_json_data(json_url:String, cache_path:String)\n",
    "# -> df: dataframe\n",
    "def get_json_data(json_url, cache_path): \n",
    "    try:        \n",
    "        f = open(cache_path, 'rb')\n",
    "        df = pickle.load(f)   \n",
    "        print('Loaded {} from cache'.format(json_url))\n",
    "    except (OSError, IOError) as e:\n",
    "        print('Downloading {}'.format(json_url))\n",
    "        df = pd.read_json(json_url)\n",
    "        df.to_pickle(cache_path)\n",
    "        print('Cached {} at {}'.format(json_url, cache_path))\n",
    "    return df\n",
    "    \n",
    "    \n",
    "#purpose: retrieve crypto data from poloniex \n",
    "#signiture: get_crypto_data(poloniex_pair:String) -> data_df: dataframe\n",
    "def get_crypto_data(poloniex_pair):\n",
    "    BASE_POLO_URL = 'https://poloniex.com/public?command=returnChartData&currencyPair={}&start={}&end={}&period={}'\n",
    "    start_date = datetime.strptime('2015-01-01', '%Y-%m-%d') # get data from start of 2015\n",
    "    ##print('START DATE:::', start_date)\n",
    "    end_date = datetime.now()\n",
    "    ##print('END DATE::: ', end_date)\n",
    "    period = 86400 # pull daily data (86,400 seconds per day)\n",
    "    \n",
    "    json_url = BASE_POLO_URL.format(poloniex_pair, start_date.timestamp(), end_date.timestamp(), period)\n",
    "    #json_url = BASE_POLO_URL.format(poloniex_pair, start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'), period)\n",
    "    \n",
    "    data_df = get_json_data(json_url, poloniex_pair)\n",
    "    data_df = data_df.set_index('date')\n",
    "    return data_df\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#----------------------------------------------------------------------\n",
    "#------------- MAIN ---------------------------------------------------\n",
    "# exchange info\n",
    "# exchanges = ['KRAKEN','COINBASE', 'BITSTAMP','ITBIT','OKCOIN', 'GETBTC']#,'COINSBANK','HITBTC','LYBIT','ANXHK','BITME','BITBOX','INTRSNG','BTCE','WEEX','JUST','CBX']\n",
    "# exch_data = {}\n",
    "\n",
    "# # retrieve exchange data and read into dictionary\n",
    "# for exchange in exchanges:\n",
    "#     exchange_df = get_quandl_data('BCHARTS/{}USD'.format(exchange))\n",
    "#     #time.sleep(1000)\n",
    "#     exch_data[exchange] = exchange_df\n",
    "    \n",
    "# # Merge BTC price data series' into single dataframe\n",
    "# btc_usd_datasets = merge_dfs_on_column(list(exch_data.values()), list(exch_data.keys()), 'Weighted Price')\n",
    "# btc_usd_datasets.replace(0, np.nan, inplace = True) # remove 0 values\n",
    "\n",
    "# # Plot all of the BTC EXCHANGE prices\n",
    "# df_scatter(btc_usd_datasets, 'Bitcoin Price (USD) by Exchange')\n",
    "\n",
    "# # Calc avg in new column\n",
    "# btc_usd_datasets['avg_btc_price_usd'] = btc_usd_datasets.mean(axis = 1)\n",
    "\n",
    "# #plot the average price \n",
    "# btc_trace = go.Scatter(x=btc_usd_datasets.index, y = btc_usd_datasets['avg_btc_price_usd'])\n",
    "# py.iplot([btc_trace])\n",
    "# ##########################################################################################\n",
    "# #                            ALT COINS\n",
    "# ##########################################################################################\n",
    "\n",
    "# # retreive alternate coin data\n",
    "# altcoins = ['ETH','LTC','XRP','ETC','STR','DASH','SC','XMR','XEM', 'GNT']\n",
    "# alt_data = {}\n",
    "\n",
    "# #change dir to poloniex_cache & create dir if it doesn't exist \n",
    "# if not 'poloniex_cache' in os.listdir(os.getcwd()):\n",
    "#     os.mkdir('poloniex_cache')\n",
    "    \n",
    "# path = os.path.join(os.getcwd(), 'poloniex_cache')\n",
    "# os.chdir(path)\n",
    "\n",
    "# for alt in altcoins:\n",
    "#     coinpair = 'BTC_{}'.format(alt)\n",
    "#     crypto_price_df = get_crypto_data(coinpair)\n",
    "#     alt_data[alt] = crypto_price_df\n",
    "\n",
    "# os.chdir('../')\n",
    "\n",
    "# # calculate USD Price as new col in each dataframe\n",
    "# for alt in alt_data.keys():\n",
    "#     alt_data[alt]['price_usd'] = alt_data[alt]['weightedAverage'] * btc_usd_datasets['avg_btc_price_usd']\n",
    "# alt_data\n",
    "# # merge price into single dataframe\n",
    "# combined_df = merge_dfs_on_column(list(alt_data.values()), list(alt_data.keys()), 'price_usd')\n",
    "# # add BTC to the dataframe\n",
    "# combined_df['BTC'] = btc_usd_datasets['avg_btc_price_usd']\n",
    "# # chart alt coins (LOG)\n",
    "# df_scatter(combined_df, 'Alternate Currency Prices (USD)', seperate_y_axis = False, y_axis_label = 'Coin Value (USD)', scale = 'linear')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
